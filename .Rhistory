input <- attributes(object)[!names(attributes(object))
%in% c("train_data", "class")]
if (!is.null(input[["seed"]])) set.seed(as.integer(input[["seed"]]))
####  update trained Halfspaces  ####
updated_hs <- update_halfspaces(object, update_data,
complete_data, n_halfspace, input)
####  get additional Halfspaces  ####
new_hs <- add_halfspaces(update_data, n_halfspace - length(object), input)
####  Return Halfspace-object  ####
halfspaces(c(updated_hs, new_hs), train_data = complete_data,
subsample = input[["subsample"]], scope = input[["scope"]],
seed = input[["seed"]], scale = input[["scale"]]
)
}
document()
document()
usethis::use_roxygen_md()
document()
document()
document()
check_man()
document()
document()
check_man()
check_man()
load_all()
library(testthat)
test_check("halflinger")
library(halflinger)
test_check("halflinger")
test_that("structure classes", {
faithful_heat <- generate_plot_faith()
expect_s3_class(faithful_heat, class = "ggplot")
expect_length(faithful_heat[["layers"]], 2)
geom_layer <- faithful_heat[["layers"]][[1]][["geom"]]
expect_s3_class(geom_layer, class = "GeomTile")
faithful_contour <- generate_plot_faith(points = FALSE, type = "contour")
expect_s3_class(faithful_contour, class = "ggplot")
expect_length(faithful_contour[["layers"]], 1)
geom_layer <- faithful_contour[["layers"]][[1]][["geom"]]
expect_s3_class(geom_layer, class = "GeomPolygon")
})
faithful_heat <- generate_plot_faith()
####  test training  ###########################################################
# use <generate_train_data> function
context("train_depth")
test_that("expect S3 class halfspace & halfspaces", {
tasks <- generate_train_data(seed0 = 345)
for (task in tasks) {
trained_hs <- do.call(train_depth, task)
expect_s3_class(trained_hs, "halfspaces")
expect_equal(validate_halfspaces(trained_hs), trained_hs)
expect_length(trained_hs, n = task$n_halfspace)
expect_named(attributes(trained_hs), expected = c("train_data", "subsample",
"scope", "scale", "class")
)
lapply(trained_hs, expect_s3_class, class = "halfspace")
}
})
tasks <- generate_train_data(seed0 = 345)
for (task in tasks) {
trained_hs <- do.call(train_depth, task)
expect_s3_class(trained_hs, "halfspaces")
expect_equal(validate_halfspaces(trained_hs), trained_hs)
expect_length(trained_hs, n = task$n_halfspace)
expect_named(attributes(trained_hs), expected = c("train_data", "subsample",
"scope", "scale", "class")
)
lapply(trained_hs, expect_s3_class, class = "halfspace")
}
trained_hs
trained_hs <- do.call(train_depth, task)
debugonce(get_halfspace)
trained_hs <- do.call(train_depth, task)
load_all()
trained_hs <- do.call(train_depth, task)
for (task in tasks) {
trained_hs <- do.call(train_depth, task)
expect_s3_class(trained_hs, "halfspaces")
expect_equal(validate_halfspaces(trained_hs), trained_hs)
expect_length(trained_hs, n = task$n_halfspace)
expect_named(attributes(trained_hs), expected = c("train_data", "subsample",
"scope", "scale", "class")
)
lapply(trained_hs, expect_s3_class, class = "halfspace")
}
####  test training  ###########################################################
# use <generate_train_data> function
context("train_depth")
test_that("expect S3 class halfspace & halfspaces", {
tasks <- generate_train_data(seed0 = 345)
for (task in tasks) {
trained_hs <- do.call(train_depth, task)
expect_s3_class(trained_hs, "halfspaces")
expect_equal(validate_halfspaces(trained_hs), trained_hs)
expect_length(trained_hs, n = task$n_halfspace)
expect_named(attributes(trained_hs), expected = c("train_data", "subsample",
"scope", "scale", "class")
)
lapply(trained_hs, expect_s3_class, class = "halfspace")
}
})
test_that("expect reproducability only if seed is set", {
tasks <- generate_train_data(seed = 345)
for (task in tasks) {
expect_identical(do.call(train_depth, task), do.call(train_depth, task))
expect_false(identical( train_depth(task[[1]]), train_depth(task[[1]])))
}
})
context("update.halfspaces")
test_that("expect S3 class halfspace & halfspaces", {
tasks1 <- generate_train_data(seed0 = 345)
for (task in tasks) {
trained_hs <- do.call(train_depth, task)
updated_hs <- update(trained_hs, task[[1]])
expect_s3_class(updated_hs, "halfspaces")
expect_equal(validate_halfspaces(updated_hs), updated_hs)
expect_length(updated_hs, n = task$n_halfspace)
expect_named(attributes(updated_hs), expected = c("train_data", "subsample",
"scope", "seed",
"scale", "class")
)
lapply(updated_hs, expect_s3_class, class = "halfspace")
}
})
tasks <- generate_train_data(seed0 = 345)
for (task in tasks) {
trained_hs <- do.call(train_depth, task)
updated_hs <- update(trained_hs, task[[1]])
expect_s3_class(updated_hs, "halfspaces")
expect_equal(validate_halfspaces(updated_hs), updated_hs)
expect_length(updated_hs, n = task$n_halfspace)
expect_named(attributes(updated_hs), expected = c("train_data", "subsample",
"scope", "seed",
"scale", "class")
)
lapply(updated_hs, expect_s3_class, class = "halfspace")
}
trained_hs <- do.call(train_depth, task)
updated_hs <- update(trained_hs, task[[1]])
debugonce(update_halfspaces)
updated_hs <- update(trained_hs, task[[1]])
task[[1]]
trained_hs
update(trained_hs, task[[1]])
debugonce(update_halfspaces)
update(trained_hs, task[[1]])
debugonce(update.halfspaces)
update(trained_hs, task[[1]])
#'    ## Scenario for a changed dataset
#'    if dataset changes, new randomly drawn subsamples are needed which provide
#'    a new base for splitpoint criteria and mass_above, therefore whole
#'    <get_halfspaces> needs to be recalled on each direction of the dataset
#'
#' @inheritParams update.halfspaces
#' @param complete_data A data set with all containing required unique
#' observations to [train_depth()]
#' @param input the parameter set an object was trained on
#' @return A data set that is ready to update [train_depth()] on
update_halfspaces <- function(object, complete_data, n_halfspace, input) {
Q
csa
)))
#'    ## Scenario for a changed dataset
#'    if dataset changes, new randomly drawn subsamples are needed which provide
#'    a new base for splitpoint criteria and mass_above, therefore whole
#'    <get_halfspaces> needs to be recalled on each direction of the dataset
#'
#' @inheritParams update.halfspaces
#' @param complete_data A data set with all containing required unique
#' observations to [train_depth()]
#' @param input the parameter set an object was trained on
#' @return A data set that is ready to update [train_depth()] on
update_halfspaces <- function(object, complete_data, n_halfspace, input) {
#'    ## Scenario for a changed dataset
#'    if dataset changes, new randomly drawn subsamples are needed which provide
#'    a new base for splitpoint criteria and mass_above, therefore whole
#'    <get_halfspaces> needs to be recalled on each direction of the dataset
#'
#' @inheritParams update.halfspaces
#' @param complete_data A data set with all containing required unique
#' observations to [train_depth()]
#' @param input the parameter set an object was trained on
#' @return A data set that is ready to update [train_depth()] on
update_halfspaces <- function(object, complete_data, n_halfspace, input) {
length_hs <-  min(length(object), n_halfspace)
if (identical(complete_data, attr(object, "train_data"))) {
warning("Output Object contains a subset of the Input Object")
return(tail(object, length_hs))
}
warning("Due to new modified Data, new splitpoints are drawn randomly")
train_depth(complete_data, n_halfspace = length_hs,
subsample = input[["subsample"]], scope = input[["scope"]],
seed = input[["seed"]], scale = input[["scale"]])
}
#' @title Add Halfspaces
))
update_halfspaces <- function(object, complete_data, n_halfspace, input) {
length_hs <-  min(length(object), n_halfspace)
if (identical(complete_data, attr(object, "train_data"))) {
warning("Output Object contains a subset of the Input Object")
return(tail(object, length_hs))
}
warning("Due to new modified Data, new splitpoints are drawn randomly")
train_depth(complete_data, n_halfspace = length_hs,
subsample = input[["subsample"]], scope = input[["scope"]],
seed = input[["seed"]], scale = input[["scale"]])
}
update(trained_hs, task[[1]])
load_all()
updated_hs <- update(trained_hs, task[[1]])
#' @title update.halfspaces
#'
#' @description Update-Method to [train_depth()] for halfspaces objects.
#'     Implementation train algorithm of Chen et al. for adding and changing
#'     `data` and amount of `halfspaces`.
#'
#' @details Functionality after input check can be summed up in 3 main steps:
#'    ## 1st Step [add_data()] & [prepare_data()]
#'    check the input on type and scale & prepare data for calculation
#'    ## 2nd Step [update_halfspaces()]
#'    update Halfspaces, already calculated in the input `object`
#'    ## 3rd Step [add_halfspaces()]
#'    get new Halfspaces
#'
#' @param object a halfspaces object containing a list arbitrary length of
#'    halfspace objects.
#' @param add logical, indicating wether `data` should be added to `train_data`
#'     from `object`
#' @inheritParams train_depth
#' @result an updated halfspaces object, reclaculated on an updated dataset
#'     and/or on a new amount of `n_halfspaces`.
#'
#' @references
#'     Chen, B., Ting, K.M., Washio, T. et al.,
#'     Mach Learn (2015): 100(2):677--699
#'     Half-space mass a maximally robust and efficient data depth method
#'     \url{https://doi.org/10.1007/s10994-015-5524-x}
#' @seealso [train_depth()], [autoplot.halfspaces()], [predict.halfspaces()]
#'
#' @export
update.halfspaces <- function(object, data = attr(object, "train_data"),
n_halfspace = length(object), add = FALSE) {
checkmate::assert_true(identical(validate_halfspaces(object), object))
checkmate::assert_true(
identical(colnames(data), colnames(attr(object, "train_data")))
)
checkmate::assert_integerish(n_halfspace, len = 1, lower = 1)
checkmate::assert_logical(add, len = 1)
complete_data <- add_data(attr(object, "train_data"),
data = data, add = add)
input <- attributes(object)[!names(attributes(object))
%in% c("train_data", "class")]
if (!is.null(input[["seed"]])) set.seed(as.integer(input[["seed"]]))
updated_hs <- update_halfspaces(object, complete_data, n_halfspace, input)
new_hs <- add_halfspaces(complete_data, n_halfspace - length(object), input)
halfspaces(c(updated_hs, new_hs), train_data = complete_data,
subsample = input[["subsample"]], scope = input[["scope"]],
seed = input[["seed"]], scale = input[["scale"]]
)
}
# utilities --------------------------------------------------------------------
#' @title Add data
#'
#' @description This function takes the observations from train data and the
#' observations from input data and returns their union amount if add is set to
#' TRUE; in addtion add_data formats the `data`.
#'
#' @param train_data the dataset a concerning `object` was trained on
#' @inheritParams update.halfspaces
#' @return A data set with all containing required unique observations to
#' [train_depth()]
add_data <- function(train_data, data, add){
if (!add) return(data)
unique(rbind(train_data, data))
}
#' @title Update Halfspaces
#'
#' @description This function updates the already drawn `halfspaces` of the
#'     input `object`.
#'
#' @details Functionality splits in two scenarios:
#'    ## Scenario for an unchanged dataset
#'    if dataset remains unchanged, halfspace objects are identical, too
#'    drawn halfspaces are a subset of `object`
#'    ## Scenario for a changed dataset
#'    if dataset changes, new randomly drawn subsamples are needed which provide
#'    a new base for splitpoint criteria and mass_above, therefore whole
#'    <get_halfspaces> needs to be recalled on each direction of the dataset
#'
#' @inheritParams update.halfspaces
#' @param complete_data A data set with all containing required unique
#' observations to [train_depth()]
#' @param input the parameter set an object was trained on
#' @return A data set that is ready to update [train_depth()] on
update_halfspaces <- function(object, complete_data, n_halfspace, input) {
length_hs <-  min(length(object), n_halfspace)
if (identical(complete_data, attr(object, "train_data"))) {
warning("Output Object contains a subset of the Input Object")
return(tail(object, length_hs))
}
warning("Due to new modified Data, new splitpoints are drawn randomly")
train_depth(complete_data, n_halfspace = length_hs,
subsample = input[["subsample"]], scope = input[["scope"]],
seed = input[["seed"]], scale = input[["scale"]])
}
#' @title Add Halfspaces
#'
#' @description This function calculates `n_halfspaces` new halfspaces from
#' `complete_data`
#'
#' @inheritParams update_halfspaces
#' @result a halfspace object of <n_halfspace> halfspaces
#'
#' @seealso [train_depth()]
add_halfspaces <- function(complete_data, n_halfspace, input) {
checkmate::assertIntegerish(n_halfspace, any.missing = FALSE, len = 1)
if (n_halfspace < 1) return(list())
do.call("train_depth", c(list(complete_data, n_halfspace), input))
}
get:wd
get_wd
get_wd()
getwd()
test()
load_all()
test()
?ggplot2::autoplot
load_all()
load_all()
install.packages(ggfortify)
install.packages("ggfortify")
load_all()
test()
document()
check_man()
check_man()
check_man()
load_all()
test()
load_all()
test()
?ggplot2::aes
?ggplot2::theme_classic
check_man()
load_all()
test()
load_all()
test()
load_all()
test()
install.packages("vdiffr")
vdiffr::expect_doppelganger("A blank plot", ggplot())
test_that("output of ggplot() is stable", {
vdiffr::expect_doppelganger("A blank plot", ggplot())
})
load_all()
test()
test()
faithful_mass <- generate_plot_faith(metric = "mass", type = "heatmap")
c("depth", "plotted in a Contour-Line-Plot", "Tukey Halfspace Depth")
%in% unlist(faithful_depth$labels, use.names = FALSE)
load_all()
test()
covr::package_coverage()
cov <- covr::package_coverage()
shine(cov)
shiny::shine(cov)
refund
refund::fosr()
refund::fosr(cov)
usethis::use_coverage()
usethis::use_coverage()
report()
library(covr)
report()
usethis::use_coverage()
faithful_heat <- generate_plot_faith(seed = 123)
faithful_heat
faithful_contour <- generate_plot_faith(points = FALSE, type = "contour",
seed = 123, scale = TRUE)
faithful_contour
faithful_depth <- generate_plot_faith(metric = "depth", type = "contour")
faithful_depth
vdiffr::expect_doppelganger("heat_unscaled_123", generate_plot_faith(seed = 123))
test()
test()
vdiffr::manage_cases
vdiffr::manage_cases()
test()
vdiffr::manage_cases()
vdiffr::manage_cases()
test()
usethis::use_coverage()
use_travis()
report()
check()
check()
roxygen2::roxygenise()
test()
check()
ggplot()
check()
check()
check()
check()
library(ggplot2)
ggplot(faithful aes(x = "eruptions", y = waiting))
ggplot(faithful, aes(x = "eruptions", y = waiting))
ggplot(faithful, aes(x = "eruptions", y = waiting)) +
geom_point()
geom_point()
check()
check()
.Last.error.trace
check()
check()
devtools::check()
devtools::build()
devtools::check()
devtools::build()
install.packages("C:/Users/Henri/Documents/C/Users/Administrator/Documents/Muenchen/LMU/R/ForPro_Hausuebung/halflinger_0.0.0.9000.tar.gz", repos = NULL, type="source")
library(halflinger)
?halflinger
halflinger::train_depth(faithful)
hs_faitful <- halflinger::train_depth(faithful)
halflinger::autoplot.halfspaces(hs_faitful, data)
halflinger::autoplot.halfspaces(hs_faitful, faithful)
halflinger::autoplot.halfspaces(hs_faitful, faithful, type = "contour")
hs_faitful <- halflinger::train_depth(faithful, scale = TRUE)
halflinger::autoplot.halfspaces(hs_faitful, faithful, type = "contour")
?halflinger::autoplot.halfspaces
?halflinger::halfspaces
library(halflinger)
?halfspaces
?halfspace
devtools::create()
getwd()
devtools::create()
library(devtools)
create()
?halflinger
document()
document()
?mlrviz
library(mlr3viz)
?mlr3viz
document()
#' @keywords internal
"_PACKAGE"
document()
?`mlr3viz-package`
document()
?autoplot.BenchmarkResult
?autoplot.PredictionClassif
load_all()
document()
load_all()
document()
?autoplot.TaskClassif
document()
data <- matrix(a = rnorm(100), b = rnorm(100, 1, 5))
data <- matrix("a" = rnorm(100), "b" = rnorm(100, 1, 5))
data <- matrix(c("a" = rnorm(100), "b" = rnorm(100, 1, 5)))
View(data)
data <- matrix(c("a" = rnorm(100)), c("b" = rnorm(100, 1, 5)))
data <- matrix(c("a" = rnorm(100)), c("b" = rnorm(100, 1, 5)))
data <- matrix(c("a" = rnorm(100), "b" = rnorm(100, 1, 5)), ncol = 2)
View(data)
train_data <- train_depth(data, seed = 123)
autoplot(train_data, data)
View(train_data)
train_data <- train_depth(data, n_halfspace = 100, seed = 123, scale = TRUE)
View(hs_faitful)
View(train_data)
attributes(train_data)
autoplot(train_data, data)
autoplot(train_data, data, type = "contour")
predict(train_data, data[1:50, ])
document()
document()
check_man()
load_all()
test()
document()
document()
document()
document()
install.packages("rmarkdown")
document()
library(halflinger)
?train_depth
document()
document()
?train_depth
check()
check()
check()
check()
check()
check()
getwd()
list.files(full.names = TRUE, recursive = TRUE)
test()
check()
build()
install.packages("C:/Users/Henri/Documents/C/Users/Administrator/Documents/Muenchen/LMU/R/ForPro_Hausuebung/halflinger_0.0.0.9000.tar.gz", repos = NULL, type="source")
?train_depth
library(halflinger)
?train_depth
?update_halfspaces
?update.halfspaces
